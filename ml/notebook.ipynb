{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WALtO2UTURT2"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GIR1V3-hUotH"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"dataset.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CJ0e0bTqUsp-"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "categorical_features = [\"job_type\", \"model\"]\n",
        "ohe = OneHotEncoder(sparse_output=False)\n",
        "categorical_encoded = ohe.fit_transform(dataset[categorical_features])\n",
        "\n",
        "numerical_features = [\"dataset_size\", \"batch_size\", \"epochs\", \"worker_cpu\", \"worker_gpu\", \"worker_mem\"]\n",
        "scaler = StandardScaler()\n",
        "numerical_scaled = scaler.fit_transform(dataset[numerical_features])\n",
        "\n",
        "x = np.hstack([numerical_scaled, categorical_encoded])\n",
        "y = dataset['runtime'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "zkUQWe-EWLiP"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMAuyg-BWWrI",
        "outputId": "495cb48a-83d5-48ad-d72d-4a7483f7c25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 7493.224, R2: 0.866\n"
          ]
        }
      ],
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import xgboost as xgb\n",
        "\n",
        "model = RandomForestRegressor(\n",
        "    n_estimators=200,\n",
        "    max_depth=15,\n",
        "    random_state=42,\n",
        "    n_jobs=1\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.3f}, R2: {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfqZJG-hW89m",
        "outputId": "fea883a1-c1e5-4786-8bd3-3a76ec43eaef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 27986.754, R2: 0.499\n"
          ]
        }
      ],
      "source": [
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=300,\n",
        "    max_depth=10,\n",
        "    learning_rate=0.1,\n",
        "    n_jobs=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(x_train, y_train)\n",
        "\n",
        "y_pred = xgb_model.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.3f}, R2: {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GBnD6HvaX5oa",
        "outputId": "e568338b-00b0-470f-e545-e53087d41177"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   7.3s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=10, n_estimators=400; total time=   7.4s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
            "[CV] END max_depth=10, min_samples_leaf=4, min_samples_split=10, n_estimators=200; total time=   2.6s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   5.2s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
            "[CV] END max_depth=10, min_samples_leaf=2, min_samples_split=10, n_estimators=300; total time=   3.9s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   9.0s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   9.2s\n",
            "[CV] END max_depth=None, min_samples_leaf=2, min_samples_split=2, n_estimators=400; total time=   7.8s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  11.7s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  11.7s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=2, n_estimators=400; total time=  11.6s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   9.6s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   8.5s\n",
            "[CV] END max_depth=20, min_samples_leaf=1, min_samples_split=5, n_estimators=400; total time=   9.7s\n",
            "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.4s\n",
            "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   6.1s\n",
            "[CV] END max_depth=15, min_samples_leaf=1, min_samples_split=10, n_estimators=300; total time=   5.1s\n",
            "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   6.9s\n",
            "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   5.7s\n",
            "[CV] END max_depth=15, min_samples_leaf=2, min_samples_split=2, n_estimators=300; total time=   7.0s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   6.2s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   7.6s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=2, n_estimators=400; total time=   6.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   7.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   6.4s\n",
            "[CV] END max_depth=20, min_samples_leaf=4, min_samples_split=5, n_estimators=400; total time=   7.6s\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "param_grid = {\n",
        "    \"n_estimators\": [200, 300, 400],\n",
        "    \"max_depth\": [10, 15, 20, None],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4]\n",
        "}\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "search = RandomizedSearchCV(rf_model, param_grid, cv=3, n_iter=10, scoring=\"r2\", verbose=2)\n",
        "search.fit(x_train, y_train)\n",
        "\n",
        "best_model = search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9-jwtfDYqfw",
        "outputId": "e703b8d3-582b-47c0-8030-1b097d18b7f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 7480.036, R2: 0.866\n"
          ]
        }
      ],
      "source": [
        "y_pred = best_model.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.3f}, R2: {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxDSFZmxZfYo",
        "outputId": "d22df706-7eb5-4f00-c7a6-b12139576d36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MSE: 18684.645, R2: 0.665\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "degree = 2\n",
        "poly_model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
        "poly_model.fit(x_train, y_train)\n",
        "y_pred = poly_model.predict(x_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f\"MSE: {mse:.3f}, R2: {r2:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4D0oDMLFds6Q",
        "outputId": "f419074a-3353-4ce3-934f-b1a86e5dcd83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['runtime_predictor.pkl']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "import joblib\n",
        "\n",
        "categorical_features = [\"job_type\", \"model\"]\n",
        "numerical_features = [\"dataset_size\", \"batch_size\", \"epochs\", \"worker_cpu\", \"worker_gpu\", \"worker_mem\"]\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), numerical_features),\n",
        "    (\"cat\", OneHotEncoder(sparse_output=False), categorical_features)\n",
        "])\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"model\", RandomForestRegressor())\n",
        "])\n",
        "\n",
        "pipeline.fit(dataset[numerical_features + categorical_features], dataset[\"runtime\"])\n",
        "joblib.dump(pipeline, \"runtime_predictor.pkl\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Proiect",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
